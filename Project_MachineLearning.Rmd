Machine Learning Final Project: Prediction of Weight Lifting Style
==================================================================

### Purpose

how machine learning algorithms are used correctly to classify exercises using data derived from accelerometers.  

### Introduction

Measure human activities using low cost accelerometers. One application of this is measuring the proper form of weight lifting (wle). We examine whether we can determine the weight lifting form using the accelerometer data collected.

### Data preparation

Download data and necessary packages
```{r warning=FALSE}
#set working directory
setwd("C:/Users/hsofoian/Desktop/DataScience/Course 8 - Machine Learning Prediction/")
setwd("./data/")

library(caret)

# Load datasets
raw_training <- read.csv("pml-training.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
raw_testing <- read.csv("pml-testing.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
```
#dim(raw_training) [1] 19622   160
#dim(raw_testing)  [1] 20      160

Create a Partition - One for training and one for cross validation. Random selection without replacement was chosen to split the data set into a training set (70%) and a cross validation set (30%).
The training and testing sets need to be large enough so that a relatively high accuracy can be achieved
```{r warning=FALSE}
set.seed(1111)
trainingIndex <- createDataPartition(raw_training$classe, list=FALSE, p=.7)
training = raw_training[trainingIndex,]
testing = raw_training[-trainingIndex,]
```
#dim(training) [1] 13737   160 (70%)
#dim(testing)  [1] 5885  160   (30%) 

Remove indicators with near zero variance.
```{r warning=FALSE}
nzv <- nearZeroVar(training)
training <- training[-nzv]
testing <- testing[-nzv]
raw_testing <- raw_testing[-nzv]
```

Filter columns to only include numeric features and outcome
```{r warning=FALSE}
num_features_idx = which(lapply(training,class) %in% c('numeric') )
```

Impute missing values as many exist in the training data.
```{r warning=FALSE}
preModel <- preProcess(training[,num_features_idx], method=c('knnImpute'))
ptraining <- cbind(training$classe, predict(preModel, training[,num_features_idx]))
ptesting <- cbind(testing$classe, predict(preModel, testing[,num_features_idx]))
prtesting <- predict(preModel, raw_testing[,num_features_idx])

#Fix Label on classe
names(ptraining)[1] <- 'classe'
names(ptesting)[1] <- 'classe'
```

### RFM - Random forest Model
A random forest model is built that is  good enough accuracy to predict the twenty test cases. 
```{r warning=FALSE}
library(randomForest)
rf_model <- randomForest(classe ~ ., ptraining, ntree=500, mtry=32)
```

### Cross Validation
We are able to measure the accuracy using our training set and our cross validation set. With the training set we can detect if our model has bias due to ridgity of our mode. With the cross validation set, we are able to determine if we have variance due to overfitting.

### In-sample accuracy
```{r warning=FALSE}
training_pred <- predict(rf_model, ptraining)
print(confusionMatrix(training_pred, ptraining$classe))
```
The sample accuracy is 100% which indicates, the model does not suffer from bias

### Out-of-sample accuracy
```{r warning=FALSE}
testing_pred <- predict(rf_model, ptesting)
```

Confusion Matrix:
```{r warning=FALSE}
print(confusionMatrix(testing_pred, ptesting$classe))
```

The cross validation accuracy is greater than 99%, which should be sufficient for predicting the twenty test observations. Based on the lower bound of the confidence interval we would expect to achieve a 98.7% classification accuracy on new data provided.

One caveat exists that the new data must be collected and preprocessed in a manner consistent with the training data.

## Test Set Prediction Results

Applying this model to the test data provided yields 100% classification accuracy on the twenty test observations.
```{r warning=FALSE}
answers <- predict(rf_model, prtesting)
answers
```

## Conclusion
We are able to provide very good prediction of weight lifting style as measured with accelerometers.
